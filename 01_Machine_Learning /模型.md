## 🤖 常見機器學習模型總整理

這裡整理了幾種我目前學過或常見的機器學習模型，包含它們是拿來做什麼的、適合什麼樣的資料，還有一些我個人的理解。

---

## 📈 1. 線性回歸（Linear Regression）

**用途：** 預測連續數值（房價、股價、溫度）

- 思想簡單：找出最符合資料的一條「直線」  
- 適合特徵與目標是線性關係的場景
- 優點：解釋性好、速度快
- 缺點：只能抓線性關係，容易 underfitting

---

## 🌳 2. 決策樹（Decision Tree）

**用途：** 分類或迴歸問題皆可（像是判斷客戶是否會流失）

- 像是問很多是非題，依特徵一步步分類
- 優點：容易視覺化、解釋性佳
- 缺點：容易 overfitting，對資料微調很敏感

---

## 🧠 3. 支援向量機（SVM, Support Vector Machine）

**用途：** 分類任務（如辨識垃圾郵件與正常信件）

- 想法是找一條「最能區分兩群」的超平面
- 優點：效果強、對高維資料友善
- 缺點：參數敏感、速度慢、不適合大資料集

---

## 🔍 4. K 最近鄰（KNN, K-Nearest Neighbors）

**用途：** 分類（ex. 手寫數字辨識）、少量資料時效果不錯

- 看新點附近的 K 個資料點，票數多的就是預測類別
- 優點：直觀、無需訓練（lazy learning）
- 缺點：資料量大時預測速度慢、對離群值敏感

---

## 🧠 5. 邏輯迴歸（Logistic Regression）

**用途：** 分類（ex. 判斷會不會中獎、患不患病）

- 雖然叫「回歸」，但其實是拿來做二分類用
- 輸出值會落在 0～1 之間（可當機率解釋）
- 優點：簡單可解釋、速度快
- 缺點：無法處理複雜非線性關係

---

## 🧪 6. Naive Bayes（樸素貝氏分類器）

**用途：** 文本分類（例如垃圾郵件辨識）、NLP 任務

- 基於機率與貝氏定理，假設各特徵之間互相獨立
- 優點：速度快、小樣本表現佳
- 缺點：假設過於簡化，可能導致準確度下降

---

## 🧠 7. 隨機森林（Random Forest）

**用途：** 分類或回歸（ex. 信用風險評估）

- 是多棵「決策樹」的平均結果（集成學習方法）
- 優點：抗 overfitting、效果穩定
- 缺點：可解釋性下降、模型龐大

---

## 🚀 8. 梯度提升樹（Gradient Boosting）

**常見框架：** XGBoost / LightGBM / CatBoost

**用途：** Kaggle 競賽常勝軍！常用於表格資料分類與預測

- 每一棵新樹都試圖修正前一棵樹的錯誤（Boosting 方法）
- 優點：準確率高、可處理不平衡資料
- 缺點：較容易 overfitting，參數多需調整

---

## 9.類神經網路（Neural Networks）

**用途：** 圖像辨識、自然語言處理、時間序列分析（幾乎萬用）

- 透過多層「神經元」進行運算模擬人類思考
- CNN：圖像處理  
- RNN / LSTM：時間序列資料（股價、語音）  
- Transformer / BERT：自然語言處理

---

## 🧾 模型選擇總覽表

| 模型名稱 | 分類任務 | 回歸任務 | 資料量適應 | 可解釋性 |
|----------|-----------|-----------|------------|-----------|
| Linear Regression | ❌ | ✅ | 小～中 | ✅✅✅ |
| Decision Tree     | ✅ | ✅ | 小～中 | ✅✅ |
| SVM               | ✅ | ✅ | 小～中 | ✅ |
| KNN               | ✅ | ✅ | 小 | ❌ |
| Logistic Regression | ✅ | ❌ | 小～中 | ✅✅✅ |
| Naive Bayes       | ✅ | ❌ | 小 | ✅✅ |
| Random Forest     | ✅ | ✅ | 中～大 | ❌ |
| Gradient Boosting | ✅ | ✅ | 中～大 | ❌ |
| Neural Networks   | ✅ | ✅ | 大 | ❌ |

---
後續會補上每個模型的實作程式碼與結果分析。


---

## 訓練模型的基本流程（挺像養成遊戲）

收集資料：越乾淨越好，像準備食材

整理資料：缺值處理、標準化（StandardScaler）、類別轉數值（OneHot）

切分資料：訓練集 / 測試集（train_test_split）

建立模型：用 scikit-learn 建一個模型

模型訓練：model.fit(X_train, y_train)

模型預測：model.predict(X_test)

評估表現：看準確率、MSE、Confusion Matrix 等

---

## 模型評估指標（怎麼知道模型有沒有學好？）
指標	適用場景	意思
Accuracy	分類	預測對的比例
Precision / Recall / F1	分類	遇到不平衡資料時更重要（如癌症偵測）
MSE / RMSE	回歸	預測值離正解的平均誤差

---

## 資料前處理

標準化（StandardScaler）：讓每個特徵平均為 0、標準差為 1（防止某些特徵影響力過大）

One-Hot Encoding：把類別變數轉成向量（ex: 男女 → [1, 0], [0, 1]）

缺值處理：可以填平均數、刪掉、或用模型預測補值
